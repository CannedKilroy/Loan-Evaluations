{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee4906f",
   "metadata": {},
   "source": [
    "# Model: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cff4e9",
   "metadata": {},
   "source": [
    "## Date: Nov 23, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48539e60",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd2a170",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead3cf15",
   "metadata": {},
   "source": [
    "For the next model, a decision tree will be used. This gives a good variety as log reg is probability based, svm distance based. It also handles non linearity well compared to linear SVM, log reg, and is a much quicker algorithm for large datasets compared to svm's. Since the last few model accuracies stagnated, there might be some non linearity in the data they are not capturing well. Therefore a decision tree is a good next model, however they can be prone to overfitting.  \n",
    "\n",
    "Unlike with the previous models, the data does not need to be scaled. As it is nonlinear, the linear assumptions dont need to be satisfied. This results in not having to check and remove features with high colinearity and multicollinearity, and therefore more features will be included in this model compared to the previous models. However, this is an advantage of decision trees, so as long this caveat is kept in mind, the comparison can still be made. \n",
    "\n",
    "The hyperparameters that can be used:  \n",
    "1. max_depth: The maximum depth of the tree. This controls overfitting as higher depth allows the model to discern more and more\n",
    "2. min_samples_split: The minimum number of samples required to split an internal node. Higher values prevent the model from learning too much detail.\n",
    "3. \n",
    "min_samples_leaf: The minimum number of samples required to be at a leaf node. Similar to min_samples_split, it controls overfittin \n",
    "4. \r\n",
    "max_features: The number of features to consider when looking for the best sp- \n",
    "5. .\r\n",
    "max_leaf_nodes: Limits the number of leaf nodes in the tree, helping to control overfiig.  \n",
    "6. g.\r\n",
    "criterion: The function used to measure the quality of a split. Common criteria include 'gini' for Gini Impurity and 'entropy' for Information G\n",
    "7. min_impurity_decrease: The minimum decrease in inpurity for the next split to be performed.  \n",
    "  \n",
    " Note: There was a visualization error with the confusion matrices. The matrix is also printedain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59320a79",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4080f086",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414e4cd7",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)\n",
    "   - [Table of Contents](#Table-of-contents)\n",
    "   - [Import Librarys](#Import-Librarys)\n",
    "   - [Data Dictionary](#Data-Dictionary)\n",
    "   - [Define Functions](#Define-Functions)\n",
    "   - [Load the data](#Load-the-data)\n",
    "3. [Decision Tree](#Decision-Tree)\n",
    "   - [1st Iteration](#1st-Iteration)\n",
    "   - [2nd Iteration](#2nd-Iteration)\n",
    "   - [3rd (Final) Iteration](#3rd-(Final)-Iteration)\n",
    "4. [Random Forest](#Random-Forest)\n",
    "5. [Conclusion](#Conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea98598-6926-4c8a-a6e6-6eed1ee711f8",
   "metadata": {},
   "source": [
    "### Import Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff8fce-5e18-4acb-86cc-75d38840ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import shap\n",
    "\n",
    "from pathlib import Path\n",
    "from joblib import dump\n",
    "from helpers import display_corr_heatmap, data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38beda3e-3ff1-409f-aa68-67f6c8ec6a50",
   "metadata": {},
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc85c466-d7aa-45de-87fb-b2ea5deab61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df824a-fa84-4091-ac8a-a2fad8458c71",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c32cd-8b3e-40ff-a3f5-3a43528c0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the relative path to the file\n",
    "parquet_file_path = Path('../Data/Lending_club/model_cleaned')\n",
    "\n",
    "try:\n",
    "    # Read the parquet file\n",
    "    loans_df = pd.read_parquet(parquet_file_path)\n",
    "except FileNotFoundError as e:\n",
    "    print(e.args[1])\n",
    "    print('Check file location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e226bbb-e1c6-449b-a628-9bdbd5981231",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d4111b-ff29-44f5-a0c1-5e4012beaf35",
   "metadata": {},
   "source": [
    "### Decision Tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa933ea-14a8-4868-b58f-49f424dfff61",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11593bb-b9f4-48fc-adf5-67b65982fbd1",
   "metadata": {},
   "source": [
    "***Train test split***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fcc531-dffb-4afe-b978-348f7048b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = loans_df.drop(columns=['loan_status'], inplace=False)\n",
    "y = loans_df['loan_status']\n",
    "\n",
    "# Split into train and test sets. Stratify to ensure any inbalance is preserved as in the original data. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a9876f-afd2-470a-adc1-7c0e492dabb7",
   "metadata": {},
   "source": [
    "***Data Inbalance***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e056a84e-75a3-4bc5-a76e-b530f7235e90",
   "metadata": {},
   "source": [
    "Decision trees are still sensitive to data inbalance, so the data will be balanced again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1946e78-33f6-4a9e-b9d9-d2d89965cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of class 1 examples before:', X_train[y_train == 1].shape[0])\n",
    "\n",
    "# Downsample majority class\n",
    "X_downsampled, y_downsampled  = resample(X_train[y_train == 1],\n",
    "                                   y_train[y_train == 1],\n",
    "                                   replace=False,\n",
    "                                   n_samples=X_train[y_train == 0].shape[0],\n",
    "                                   random_state=1)\n",
    "\n",
    "print('\\nNumber of class 1 examples after:', X_downsampled.shape[0])\n",
    "\n",
    "# Combine the downsampled successful loans with the failed loans. Will keep as a df since changing to \n",
    "X_train_bal = pd.concat([X_train[y_train == 0], X_downsampled])\n",
    "y_train_bal = np.hstack((y_train[y_train == 0], y_downsampled))\n",
    "\n",
    "print(\"New X_train shape: \", X_train_bal.shape)\n",
    "print(\"New y_train shape: \", y_train_bal.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d555aab1-e9b2-4e1b-acd0-3c54033fb383",
   "metadata": {},
   "source": [
    "No features need to be dropped so there are now 25 extra features that were not available in log reg and svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb62c3-5d96-40dd-914b-04e71585c875",
   "metadata": {},
   "source": [
    "***Inspect Categorical Features***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889cbacc-7ce1-4911-8697-7731a438c334",
   "metadata": {},
   "source": [
    "Categorical features have to be numerically encoded. The encodings will be the same as the other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d1568-3367-4fb8-b5ec-8a2ff1d8d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = X_train_bal.select_dtypes('object').columns.tolist()\n",
    "display(categorical_columns)\n",
    "categorical_columns.remove('verification_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb566fe-5ff6-451d-af2a-73644f037d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "ordinal_transformer = OrdinalEncoder(categories=[['Not Verified', 'Source Verified', 'Verified']])\n",
    "\n",
    "# Combine into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, ['home_ownership', 'verification_status', 'purpose', 'application_type']),\n",
    "        ('ord', ordinal_transformer, ['verification_status'])],\n",
    "    remainder='passthrough',\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "# Fit to the train set\n",
    "preprocessor.fit(X_train_bal)\n",
    "\n",
    "# Transform the train and test sets\n",
    "X_train_transformed = preprocessor.transform(X_train_bal)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Shape of train transformed: \", X_train_transformed.shape)\n",
    "print(\"Shape of test transformed: \", X_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549b296d-a513-4ff3-ae9f-603fb3b28440",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35476edb-799c-4901-b7fb-1b21d71780a6",
   "metadata": {},
   "source": [
    "### 1st Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167ea232-9dbd-4c05-80ba-eacdd379afbf",
   "metadata": {},
   "source": [
    "Since there are so many hyperparameters for decision trees, it does not make sense to manually iterate one by one to find acceptable hyperparameter ranges for the final iteration, like what was done for log reg and svm. Instead, a randomized gridsearch, which simply computes random combinations of hyperparameters, is more efficent. This works like the GridsearchCV function seen in the other notebooks, however it simply takes a random sample of hyperparamter combinations, as opposed to an exhaustive search. This saves on computations and time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996b9f12-98e5-4704-9c83-66659686e2c0",
   "metadata": {},
   "source": [
    "***Run the first iteration***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b6d502-e4c4-4a28-bb7e-0457b40613ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate decision tree\n",
    "dt_classifier = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Hyperparameters grid to search\n",
    "param_dist = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [None, 7, 8, 9],\n",
    "    \"min_samples_split\": [4,5,6],\n",
    "    \"min_samples_leaf\": [9, 10, 11],\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, average='weighted'),\n",
    "    'f1': make_scorer(f1_score, average='binary', pos_label=1) #f1 score for class 1\n",
    "}\n",
    "\n",
    "# Randomized Grid Search with cross-validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    dt_classifier, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=100, #pull out 100 combinations\n",
    "    scoring=scoring, \n",
    "    refit='f1', #refit on f1 for class 1\n",
    "    cv=5, #5 fold cross validation\n",
    "    random_state=1, \n",
    "    verbose=10,\n",
    "    n_jobs=3 #adjust based on your cpu cores\n",
    ")\n",
    "\n",
    "# Fit\n",
    "random_search.fit(X_train_transformed, y_train_bal)\n",
    "\n",
    "# Best model\n",
    "best_dt_model = random_search.best_estimator_\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81b80d-a722-485c-902f-e8ae6b0e8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bdcc69-2233-4265-a87c-9c3706915347",
   "metadata": {},
   "source": [
    "***Score the first iteration***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725dd99-cf6e-4248-b031-6b3cdb432eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on both training and test data\n",
    "y_pred_train = best_dt_model.predict(X_train_transformed)\n",
    "y_pred_test = best_dt_model.predict(X_test_transformed)\n",
    "\n",
    "# Calculate accuracies for train and test sets\n",
    "train_accuracy = accuracy_score(y_train_bal, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Print the train and test accuracies\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Check for any overfitting\n",
    "if train_accuracy > test_accuracy:\n",
    "    print(\"The model might be overfitting.\")\n",
    "else:\n",
    "    print(\"The model seems to generalize well.\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"Confusion maxtrix\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7d7a8-c4e3-48f0-8a29-3eba7a0a406e",
   "metadata": {},
   "source": [
    "***1st model Interpretation***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15ba66-43c9-44b1-9ba3-f4a0379b07ee",
   "metadata": {},
   "source": [
    "For the first iteration, there is noticeable overfitting. The model underperformed relative to the baseline log reg model, even though it was observed that there were many non linear relationships. The weighted average F1 score, a good overall metric, is lower than log reg's 0.69.\n",
    "Overall, the model overfit, and underperformed. A tree depth of 8 is quite high and will be adjusted next to control the overfitting. Further interpretation will be done once the model generalizes well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50af9d3-c069-4006-8d06-3a630084d26a",
   "metadata": {},
   "source": [
    "***1st model Feature importance***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1be1ec-8069-42a5-9b88-1fc51794cb02",
   "metadata": {},
   "source": [
    "For log reg, the coefficients gave information on how much predictability a feature had. With a decision tree, feature importance is calculated based on the features ability to reduced impurity, ie segment the data into \"pure\" buckets. Impurity is a measure of the homogeneity of the labels at a node. Features that are able to greatly reduce impurity, ie are great discerners for the different classes, are given a high importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b186eb-bf9b-4ee9-a825-cda0fb806240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "feature_names_transformed = preprocessor.get_feature_names_out()\n",
    "print(type(feature_names_transformed))\n",
    "\n",
    "# Get importances \n",
    "importances = best_dt_model.feature_importances_\n",
    "\n",
    "# Sort and get indices\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# PLot\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(X_train_transformed.shape[1]), importances[indices], color=\"r\")\n",
    "plt.yticks(range(X_train_transformed.shape[1]), feature_names_transformed[indices])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1b1513-7224-42d2-b7ea-b372840c0232",
   "metadata": {},
   "source": [
    "Interest rate has the highest importance by far. This was initially worrisome, however, interest rate is not a leaky feature. Instead, it is possible that the larger financial burden brought on by a larger interest rate is enough to force a loan default. However, this is purely speculation and investigated below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4960d-810d-4395-9a40-6b9c32c2df28",
   "metadata": {},
   "source": [
    "***Tree Diagram***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a886ad-9a1d-4858-9d8b-417eee64580c",
   "metadata": {},
   "source": [
    "Due to the depth, the tree will be truncated at a layer of 4 for visualization.  \n",
    "https://mljar.com/blog/visualize-decision-tree/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dbbaa9-2908-48e8-b8a0-5fe60f252227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a list\n",
    "feature_names_list = feature_names_transformed.tolist()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(best_dt_model, \n",
    "          feature_names=feature_names_list, \n",
    "          class_names=['Class 0', 'Class 1'], \n",
    "          filled=True, \n",
    "          rounded=True, \n",
    "          fontsize=12,\n",
    "          max_depth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6504a43-e5d4-46b3-b0d3-13569835561b",
   "metadata": {},
   "source": [
    "The root is split based off of interest rate, the highest importance feature. This split makes sense, as seen in EDA, the median interest rate for failed loans was 15% whereas for successful loans it as 12%, making it a good discriminator. For failed loans, the next features were the loan term and annual income. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa4b2a-d53c-4bcb-b614-bb1365911a80",
   "metadata": {},
   "source": [
    "### 2nd Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96813c66-989c-4b18-9749-d91de6277818",
   "metadata": {},
   "source": [
    "Now that there is a baseline decision tree model, we can now vary max depth manually to address the overfitting. Max depth is the most important parameter for controlling overfitting, as it places a limit on how many times the tree can split, thus increasing its purity. Limiting max depth stops the tree from over capturing the noise on the train set, allowing it to better generalize to other data. The previous best model will be used, and the C value iterated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b1fef-4e14-4b05-84fe-f1d0048467b0",
   "metadata": {},
   "source": [
    "***Run the model 2nd Iteration***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b57073-0f3c-41d6-bd68-eb2844171189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define lists for accuracies to be plotted\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "f1_scores_train = []\n",
    "f1_scores_test = []\n",
    "\n",
    "# Depth of 10 to 2 backwards \n",
    "for depth in range(10, 1, -1):\n",
    "    \n",
    "    # Set max_depth\n",
    "    best_dt_model.set_params(max_depth=depth)\n",
    "    \n",
    "    # Fit \n",
    "    best_dt_model.fit(X_train_transformed, y_train_bal)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = best_dt_model.predict(X_train_transformed)\n",
    "    y_pred_test = best_dt_model.predict(X_test_transformed)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train_bal, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Calculate F1 scores\n",
    "    f1_train = f1_score(y_train_bal, y_pred_train, average='binary', pos_label=1)\n",
    "    f1_test = f1_score(y_test, y_pred_test, average='binary', pos_label=1)\n",
    "    \n",
    "    # Append to lists\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    f1_scores_train.append(f1_train)\n",
    "    f1_scores_test.append(f1_test)\n",
    "    \n",
    "    # Print the results for this iteration\n",
    "    print(f\"Max depth: {depth}\")\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Train F1 Score: {f1_train:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1_test:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b93f9-ea1b-4c6f-82a5-d6c3048b2e2d",
   "metadata": {},
   "source": [
    "***2nd model interpretation***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4833e9-f5c5-4309-b8df-c98b01951d4e",
   "metadata": {},
   "source": [
    "Since the 2nd iteration only focus's on addressing the overfitting, only the train and test scores really need to be evaluated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609bc772-0d24-4a54-ac53-79ae7bec5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = list(range(10, 1, -1))\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot train and test accuracies\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(depths, train_accuracies, marker='o', label='Train Accuracy')\n",
    "plt.plot(depths, test_accuracies, marker='*', label='Test Accuracy')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracies by Max Depth')\n",
    "plt.legend()\n",
    "plt.gca().invert_xaxis()  # Invert x-axis\n",
    "\n",
    "# Plot F1 scores\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(depths, f1_scores_train, marker='o', label='Train F1 Score for class 1')\n",
    "plt.plot(depths, f1_scores_test, marker='*', label='Test F1 Score for class 1')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Train/Test F1 Scores by Max Depth for class 1')\n",
    "plt.legend()\n",
    "plt.gca().invert_xaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceea787-dd4c-465f-90a6-ae8d1d0bb531",
   "metadata": {},
   "source": [
    "A depth of 4 seems optimal. The train and test accuracies converge, and the f1 score was the highest for the test set. Below a depth of 4 the tree is too shallow to perform well, and above 4 the model overfits and fails to generalize well to the test set. The model also achieves the highest f1 score as well at a depth of 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6b254-0b93-45ac-8660-90cc15a03837",
   "metadata": {},
   "source": [
    "### 3rd (Final) Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c3395-8915-428d-8dc2-d659e70a38f5",
   "metadata": {},
   "source": [
    "Having established a good range for a few hyperparameters, we can now run an exhaustive search for the best combination. Recall the best parameters found were:  \n",
    "\n",
    "\n",
    "- 'criterion':entropy    \n",
    "- 'min_samples_split': 65\n",
    "- 'min_samples_leaf': 10\n",
    "- 'max_features': None\n",
    "- 'max_depth':84\r",
    "  \n",
    "Max depth will be fixed at 4, as this was found to be optimal, however it is not the only hyperparameter that has a large impact on the models fit. Other hyperparameters also control the models fit, so fixing max depth to 4 does not automatically equate to a possible poor fitting model or guarantee no model overfitting. \n",
    "\n",
    "The previous models were fit on class 1 f1 scores, in order to give a range that would lead to a better fitting model overall, and not too narrow if only optimized for precision. However, unlike log reg, there is no threshold that can be modified after the fact to favor precision or recall, so the final model will now be optimized for class 1 precision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a351c02-77c2-4730-ada3-d77a55bee2aa",
   "metadata": {},
   "source": [
    "More information on features to control overfitting and important hyperparameters:  \n",
    "https://blog.dataiku.com/narrowing-the-search-which-hyperparameters-really-matter  \n",
    "https://medium.com/@ompramod9921/decision-trees-8e2391f93fa7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b698a23a-4af6-4e0b-bed1-af830a1f2c25",
   "metadata": {},
   "source": [
    "***Run the model 3rd (Final) Iteration***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae4e0f8-9969-4feb-8240-216ba777add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate\n",
    "dt_classifier = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Hyperparameters\n",
    "param_grid = {\n",
    "    \n",
    "    # Keep fixed\n",
    "    \"criterion\": [\"entropy\"],\n",
    "    \"max_depth\": [4],\n",
    "\n",
    "    # Increase to reduce overfitting\n",
    "    \"min_samples_split\": [7,8],\n",
    "    \"min_samples_leaf\": [11,12],\n",
    "}\n",
    "#Best parameters from last iteration: {'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': None, 'max_depth': 8, 'criterion': 'entropy'}\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, pos_label=1, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, pos_label=1, average='weighted'),\n",
    "    'f1': make_scorer(f1_score, pos_label=1, average='binary')\n",
    "}\n",
    "\n",
    "# Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    dt_classifier, \n",
    "    param_grid=param_grid, \n",
    "    scoring=scoring, \n",
    "    refit='precision', # Refit on precision score for class 1 now\n",
    "    cv=5, \n",
    "    verbose=10,\n",
    "    n_jobs=3)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train_transformed, y_train_bal)\n",
    "\n",
    "# Best model\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6837c-1625-48f4-95dd-071627b27566",
   "metadata": {},
   "source": [
    "***Score the model 3rd (Final) Iteration***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c92040-f357-4a78-a6be-50cdfba5f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the training set and the test set\n",
    "y_train_pred = best_dt_model.predict(X_train_transformed)\n",
    "y_test_pred = best_dt_model.predict(X_test_transformed)\n",
    "\n",
    "# Calculate accuracies for train and test sets\n",
    "train_accuracy = accuracy_score(y_train_bal, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the train and test accuracies\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for the Test Set')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# AUC score and ROC curve for the test set\n",
    "y_test_proba = best_dt_model.predict_proba(X_test_transformed)[:, 1]\n",
    "auc_score = roc_auc_score(y_test, y_test_proba)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "print(conf_matrix_test)\n",
    "print('AUC score: ', auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468a7a12-6c8d-47f5-bfa4-665d637d6a0a",
   "metadata": {},
   "source": [
    "For the final iteration, we saw a large improvement. The train and test scores are very similar, showing there is no longer any overfitting. Both min_samples_split and min_samples_leaf were increased to help with the issue. However, no improvement was made over the baseline log reg model. For class 1, the same precision of 0.87 was achieved, with a 0.02 decrease in recall. Similarly, for class 0, the precision and recall were slightly worse compared to the baseline. Overall, the weighted average f1 score and AUC dropped by 0.02.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3561eab-af81-4111-b75c-7d17d0774eb3",
   "metadata": {},
   "source": [
    "***3rd model Feature Importance***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0624c6-96e4-4d49-8983-0237f407255f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "feature_names_transformed = preprocessor.get_feature_names_out()\n",
    "print(type(feature_names_transformed))\n",
    "\n",
    "# Get importances \n",
    "importances = best_dt_model.feature_importances_\n",
    "\n",
    "# Sort and get indices\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# PLot\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(X_train_transformed.shape[1]), importances[indices], color=\"r\")\n",
    "plt.yticks(range(X_train_transformed.shape[1]), feature_names_transformed[indices])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a5a30-c472-4d8f-82d5-69ace6a18cac",
   "metadata": {},
   "source": [
    "Once again, the model is very concentrated on what features is relies on. Interest rate is of the highest. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e5357-9cf7-44a8-ba97-5ee8060fa241",
   "metadata": {},
   "source": [
    "***3rd model Tree Diagram***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d050af2a-0b4b-4f39-94d5-e89209d69cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a list\n",
    "feature_names_list = feature_names_transformed.tolist()\n",
    "\n",
    "plt.figure(figsize=(28,14))\n",
    "plot_tree(best_dt_model, \n",
    "          feature_names=feature_names_list, \n",
    "          class_names=['Class 0', 'Class 1'], \n",
    "          filled=True, \n",
    "          rounded=True, \n",
    "          fontsize=12,\n",
    "          max_depth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce296f7-c89b-486e-aae5-ae8d51338bf4",
   "metadata": {},
   "source": [
    "***3rd model SHAP values***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa150b16-fa5d-4c3b-b40a-106f10a2876f",
   "metadata": {},
   "source": [
    "SHAP values are based on game theory and assign an importance value to each feature in a model. Features with positive SHAP values positively impact the prediction, while those with negative values have a negative impact. The magnitude is a measure of how strong the effect is.  \n",
    "\n",
    "It has a similar function to the feature importance plot above, however, it gives more infomation as well. \n",
    "  \n",
    "https://www.datacamp.com/tutorial/introduction-to-shap-values-machine-learning-interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae4b148-97ab-45a2-a5d5-34e5ff678b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# https://www.kaggle.com/code/dansbecker/shap-values\n",
    "# Instantiate\n",
    "explainer = shap.TreeExplainer(best_dt_model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer(X_test_transformed)\n",
    "\n",
    "# Selects the SHAP values for the positive class\n",
    "shap_values_positive_class = shap_values[..., 1] \n",
    "\n",
    "# Plot\n",
    "shap.summary_plot(shap_values_positive_class, X_test_transformed, feature_names=feature_names_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f22e4-b18e-40e3-a932-786715211594",
   "metadata": {},
   "source": [
    "The summary plot shows the contribution of each feature to the model, for each sample. Each dot refers to a specific loan in the dataset. The color represents the value of the feature, ie, blue indicating lower feature values, red higher. Where on the x axis the dot lies indicates if it was a positive or negative impact, and the magnitude. SHAP values range from -1 to +1.  If there are many dots overlapping, they are seperated sligtly vertically. These plots give far more information compared to the feature importances calculated a few cells above.\n",
    "\n",
    "For the `int_rate` feature, higher interest rates (in red) tend to have more negative shap values, indicating it pushes the prediction towards the negative class (failed loans). The vice versa is also true; a lower interest rate pushes prediction towards the positive class. Although the color gradient left to right is consistent, there are groupings of interest rates at different shap values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a9b99-9160-4181-8c5c-553a871cc735",
   "metadata": {},
   "source": [
    "***Save the 3rd (Final) Iteration***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae3d85-de70-4f2c-8053-0d9eafa3f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative path to models folder\n",
    "model_file_path = Path('../Models/best_decision_tree_model.joblib')\n",
    "dump(best_dt_model, model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb5219-26c0-413e-9cd9-9e4348fadd43",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b5aab-50b2-4010-afc6-adb1b945a13a",
   "metadata": {},
   "source": [
    "We can now use a ensemble of decision trees called random forest. It uses the bootstrapping technique. A random sample of the dataset is taken, with replacement, and then a tree is trained on each sample. The theory is that, since the trees are trained on different datasets and that decision trees in general are quite sensitive to small changes in the data, diversity is introduced into the model which helps with the overfitting we experienced above. Max features will also be introduced \n",
    "\n",
    "This forest of trees are then aggregated back together for predictions. The consensus protocol is usually a simple majority vote among the trees for classification problems. \n",
    "\n",
    "In addition to the hyperparameters for a single decision tree, random forest has:\n",
    "- n_estimators: The number of trees in the forest. Generally, a larger number of trees increases performance but at a computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a599b4-feb6-455d-a907-401db2e3eb24",
   "metadata": {},
   "source": [
    "***Fit the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d56bb4-3467-4002-969c-5d207220ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Hyperparameters grid to search\n",
    "forrest_param_grid = {\n",
    "    # Keep fixed\n",
    "    \"criterion\": [\"entropy\"],\n",
    "    \"max_depth\": [4,5],\n",
    "\n",
    "    # Increase to reduce overfitting\n",
    "    \"min_samples_split\": [7, 8],\n",
    "    \"min_samples_leaf\": [12, 13],\n",
    "\n",
    "    # Parameters for Random Forest\n",
    "    \"n_estimators\": [150],  # Number of trees in the forest. 100 is default\n",
    "    \"max_features\": ['sqrt', 'log2'],  # Number of features to consider at every split\n",
    "    #max_features{“sqrt”, “log2”, None}, int or float, default=”sqrt”\n",
    "\n",
    "}\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, pos_label=1, average='binary'),\n",
    "    'recall': make_scorer(recall_score, pos_label=1, average='binary'),\n",
    "    'f1': make_scorer(f1_score, pos_label=1, average='binary')\n",
    "}\n",
    "\n",
    "# Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    rf_classifier, \n",
    "    param_grid=forrest_param_grid, \n",
    "    scoring=scoring, \n",
    "    refit='precision',  # Refit on precision score for class 1\n",
    "    cv=5, \n",
    "    verbose=10,\n",
    "    n_jobs=3  # Using -1 to use all processors\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train_transformed, y_train_bal)\n",
    "\n",
    "# Best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae019d37-d8a4-453c-8489-471e37ab6e4e",
   "metadata": {},
   "source": [
    "***Score the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d9831-42da-4fb3-a362-0947b1102d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = best_rf_model.predict(X_train_transformed)\n",
    "y_test_pred = best_rf_model.predict(X_test_transformed)\n",
    "\n",
    "# Calculate accuracies for train and test sets\n",
    "train_accuracy = accuracy_score(y_train_bal, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "if train_accuracy > test_accuracy:\n",
    "    print(\"The model might be overfitting.\")\n",
    "else:\n",
    "    print(\"The model seems to generalize well.\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate scores\n",
    "y_test_proba = best_rf_model.predict_proba(X_test_transformed)[:, 1]\n",
    "auc_score = roc_auc_score(y_test, y_test_proba)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (area = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa03ec7-1df3-4268-acd6-a0a105d76c14",
   "metadata": {},
   "source": [
    "The model's class 1 precision increased from 0.87 to 0.88, however, there is some slight overfitting. On the otherhand, recall dropped by 0.02, with the AUC staying constant. This is the best fitting model, in terms of precision, so far. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4217d47-62d8-40a6-824b-54455a14ff96",
   "metadata": {},
   "source": [
    "***Save the Random Forest model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c0d15a-7984-4c45-90f8-3aaac0a62737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative path to models folder\n",
    "model_file_path = Path('../Models/best_random_forest_model.joblib')\n",
    "dump(best_rf_model, model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f13bcff-86ce-4271-b497-49d93b0908ec",
   "metadata": {},
   "source": [
    "***RF model SHAP values***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7fee3b-beb6-4854-bb8a-7f7ae2ee58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "feature_names_transformed = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Instantiate\n",
    "explainer = shap.TreeExplainer(best_rf_model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer(X_test_transformed)\n",
    "\n",
    "shap_values_positive_class = shap_values[..., 1]\n",
    "\n",
    "# For a global understanding, use the summary plot for the positive class\n",
    "shap.summary_plot(shap_values_positive_class, X_test_transformed, feature_names=feature_names_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a27a2-aa1e-4c4f-9538-9d198ff823df",
   "metadata": {},
   "source": [
    "Interest rate is once again a good predictor. Shorter loan terms have a positive impact on the prediction, similar to the debt to income ratio. A low value in the label-encoded `cat__verification_status_not verified` means the loan has some verification and the feature has a positive impact on the prediction. These examples show how powerful the shap plots are, as they show different points in the features distribution effects the model prediction This is incredibly important to both the investor and borrower as the investor can better justify the decision for extending or withholding credit, increasing both accountability and transparancy. Futhermore, it allows the investor to see how exactly the features are influencing the model, and therefore is make the decision on keeping, removing, or engineering the feature to better.  \n",
    "\n",
    "The shap plot for the random forest shows a wider distribution of important features compared to that of a single tree. For the single best optimized tree, interest rate was the only really important feature. However, for random forest there are many. This variety results in a model that is less dependent on a single features value, resulting in a more stable model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4521d249-c7e3-4c9f-b8c8-e85c46826f1d",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b39ca-5d29-40e4-99d0-e4ee69643140",
   "metadata": {},
   "source": [
    "In this notebook, we explored fitting decision trees and a random forest to our data. For decision trees, a random gridsearch was conducted to get ballpark ranges for hyperparameter values. However, since the model was overfitting, the max depth was manually varied and explored. A depth of 4 was shown to be optimal, achieving high metrics without excessive overfitting. An exhaustive gridsearch was then done based on the previous 2 iterations. This final model showed a large improvement over the previous iteration, however, no improvement over the baseline log reg was made. Finally, a random forest model was fit to the data. This model showed almost exactly the same metrics, however the model is far more stable and less dependent on only a few features. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loans_capstone",
   "language": "python",
   "name": "loans_capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
