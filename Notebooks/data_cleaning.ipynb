{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9533d898-2c8f-4b1a-a1fe-8dcf42bf4abf",
   "metadata": {},
   "source": [
    "\n",
    "TODO:\n",
    "* Function for remove a set of columns / rows and check theyve been removed by returning bool\n",
    "* Can do PCA but mostly note for financial loan data as its very hard to be explainable. Can maybe save it for later\n",
    "* Can do stratify Y\n",
    "* Write a helper func to display the data dict\n",
    "* verify drop hardship loans works\n",
    "* pyment_plan variation is low, do vif. May also be leaky if its put inplace after. It is\n",
    "* title vs purpose. Both are good. Drop one\n",
    "* func that takes in some columns and returns the data dict entry for them\n",
    "* check disbursement_method\n",
    "* initial_list_status ie https://www.fintechnexus.com/lending-club-whole-loan-program-one-year-later/\n",
    "* Drop issue_d after EDA\n",
    "* Make the columns to drop into a list, so that i can keep track and seperate which oclumns im dropping and why\n",
    "* funded_amnt', 'funded_amnt_inv\n",
    "* - Loan-to-income ratio\n",
    "* when loading in the data make it to select inplace\n",
    "* Policy code 2\n",
    "* ***Amount Loan was funded for***\n",
    "We will drop the funded amount as it leaks that the loan has passed the application process.\n",
    "#sample_accepted_df.drop(columns = ['funded_amnt', 'funded_amnt_inv'], inplace=True)\n",
    "* pip list --format=freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a87e7-3f0f-49cd-bf5c-740bc94a1a17",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a19a03-c85e-4502-b298-c85101ef9b6e",
   "metadata": {},
   "source": [
    "## Date: OCT 10, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f4e8ea",
   "metadata": {},
   "source": [
    "-- ------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1715de5e-0908-4ff3-82ce-246ed69273ca",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7606bb8-f8a4-4c60-85ef-858832c9e883",
   "metadata": {},
   "source": [
    "This notebook cleans the data for the lending club accepted loans, then exports the data as a parquet file. Due to the size of the dataset, the csv is read in chunks, with a random sample taken from each each chunk. Only fully paid and charged off / defaulted loans are sampled as current loans hold no value in classifying the target variable. This allows us to more efficiently load the data. Those samples are merged and will become the working dataset for the duration of the project. After unnecessary and leaky features are removed, features are formatted and null values dealt with. Finally the dataframe is size is optimized and exported.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1701fc-f92e-4bd9-a8f3-b9c891eadf34",
   "metadata": {},
   "source": [
    "### Table-of-contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bbe9b1-8cfd-4215-b9ca-6ec5d9a2b7e7",
   "metadata": {},
   "source": [
    "\n",
    "1. [Introduction](#Introduction)\n",
    "   - [Table-of-contents](#Table-of-contents)\n",
    "   - [Import-Librarys](#Import-Librarys)\n",
    "   - [Data Dictionary](#Data-Dictionary)\n",
    "   - [Define-Functions](#Define-Functions)\n",
    "   - [Load in the data](#Load-the-data)\n",
    "3. [Data Cleaning](#Data-Cleaning)\n",
    "   - [Initial Exploration](#Initial-Exploration)\n",
    "   - [Feature Pruning](#Feature-Pruning)\n",
    "   - [Explore Columns to drop](#Explore-Columns-to-drop)\n",
    "   - [Dataframe Null Values](#Dataframe-Null-Values)\n",
    "4. [Dataframe optimization](#Dataframe-optimization)\n",
    "5. [Exploratory-Data-Analysiss](Exploratory-Data-Analysis)\n",
    "6. [Feature Engineering](#Feature-Engineering)\n",
    "7. . [Conclusion](#Conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9252c44",
   "metadata": {},
   "source": [
    "### Import-Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97841a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas-downcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f7014-7a9b-41ed-a7dd-e6f6c419074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890b8ae-7ed0-4e0e-88a8-d33a33f5ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run helpers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from helpers import full_display\n",
    "import pdcast as pdc\n",
    "#import missingno as msno\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17654b3a-269f-4d42-a4c3-b10a8873d67a",
   "metadata": {},
   "source": [
    "### Data-Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d7734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2aa2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pathlib is used to ensure compatibility across operating systems\n",
    "try:\n",
    "    data_destination = Path('../Data/Lending_club/Lending Club Data Dictionary Approved.csv')\n",
    "    dict_df = pd.read_csv(data_destination, encoding='ISO-8859-1')\n",
    "    display(dict_df.iloc[:,0:2])\n",
    "except FileNotFoundError as e:\n",
    "    print(e.args[1])\n",
    "    print('Check file location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c720f-9f8a-490c-9bcc-5c84aa28e660",
   "metadata": {},
   "source": [
    "#### Define-Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcadaa11-002e-41ea-a2a9-925a4e5a3e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_emp_length(string):\n",
    "    if string == '< 1 year':\n",
    "        return 0.5\n",
    "    elif string == '10+ years':\n",
    "        return 10\n",
    "    elif 'years' or 'year' in string:\n",
    "        return int(string.split()[0])\n",
    "    elif string == '0':\n",
    "        return 0\n",
    "    else:\n",
    "        return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf7abd-8cce-4099-b670-73456af6d1a8",
   "metadata": {},
   "source": [
    "When initially loading in the dataset, Pandas raised a DtypeWarning over mixed datatypes within various columns. Setting low_memory = False while breaking the CSV into chunks allows Pandas to load an entire chunk before guessing the data types. When the script to scrape the data dictionary is finished, the data dict can then be passed in instead of relying on pandas. The mixed_data_types function is stilled called as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e3869-47e5-4e04-b89b-ebbe8a4da053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_data_types(df:pd.DataFrame) -> bool:\n",
    "    '''\n",
    "    Takes in a dataframe and checks for columns with mixed data types\n",
    "    If none are found return False, else True\n",
    "    \n",
    "    :param df: The dataframe to be checked\n",
    "    :type df: obj\n",
    "    :return bool: True if found, false if none were found\n",
    "    :type return: bool\n",
    "    '''\n",
    "    \n",
    "    #loop through each column\n",
    "    for column in df:\n",
    "\n",
    "        #filter outint datatypes coming from Nan and get unique data types\n",
    "        unique_types = df[column].dropna(inplace=False).apply(type).unique()\n",
    "\n",
    "        #if there are more than 1 datatype in a column\n",
    "        if unique_types.size > 1:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b1603-308a-4ddb-9766-594feac1245a",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a42820-7bc4-4790-81d5-ef808754cd70",
   "metadata": {},
   "source": [
    "Due to the size of the dataset, it is read in chunks. After each chunk is read and checked for mixed data types, it is randomly sampled and then placed within a list. Only fully paid and /defaulted and charged off loans are taken, as current loans including late or in grace period loans do not hold any value in target variable prediction. This is done when loading in the data otherwise it becomes too large for memory. The different samples are then combined into a single sample representative of the whole dataset. EDA will be performed on this single sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d90c2-bd23-4f8a-9a9e-c3ce8acbaab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 5*100000\n",
    "sample_size =  100000\n",
    "random_state = 11\n",
    "\n",
    "assert sample_size < chunk_size, f\"Cannot take a sample of {sample_size} rows out of {chunk_size} rows\"\n",
    "\n",
    "print(f'Chunk size: {chunk_size} rows')\n",
    "print(f'Rows to be sampled: {sample_size} rows')\n",
    "\n",
    "\n",
    "sampled_dataframes = []\n",
    "try:\n",
    "    data_destination = Path('../Data/Lending_club/accepted_2007_to_2018Q4.csv')\n",
    "\n",
    "    #split the csv into chunks and iterate over each chunk\n",
    "    with pd.read_csv(data_destination, chunksize=chunk_size, low_memory = False) as reader:\n",
    "        for count,chunk in enumerate(reader):\n",
    "            \n",
    "            if mixed_data_types(df=chunk) == True:\n",
    "                raise Exception(\"Mixed data types found\")\n",
    "\n",
    "            #define a list that includes only finished loan statuses\n",
    "            finished_loan_status = ['Fully Paid',\n",
    "                                    'Charged Off',\n",
    "                                    'Does not meet the credit policy. Status:Fully Paid',\n",
    "                                    'Does not meet the credit policy. Status:Charged Off',\n",
    "                                    'Default']\n",
    "                        \n",
    "            #filter the dataframe for loans that are finished or null\n",
    "            filtered_chunk = chunk.loc[chunk['loan_status'].isin(finished_loan_status) | chunk['loan_status'].isnull()]\n",
    "            \n",
    "            #sample the filtered df and append to list\n",
    "            sampled_df = filtered_chunk.sample(n=sample_size, random_state=random_state)\n",
    "            sampled_dataframes.append(sampled_df)\n",
    "            \n",
    "            print(f\"{count} sampled dataframe shape: {sampled_df.shape}\")\n",
    "        print('Finished')\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e.args[1])\n",
    "    print('Check file name and location')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e.args[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf972fc-423c-4d4e-86fa-af16729ef0b3",
   "metadata": {},
   "source": [
    "There are no duplicate datatypes within any columns. The random samples can be combined into a single sample dataframe. This sample will be used as the working dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd48046-7d83-4aa7-86b1-66d7349cb708",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df = pd.concat(sampled_dataframes, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee15a8a-69e1-4da0-9062-fe55b7fea232",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08d900-4c61-4f28-a187-b678483e509b",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f56533c-c67d-44e3-a7ad-45481efa64bc",
   "metadata": {},
   "source": [
    "### Initial Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec421c-5836-454e-b624-d2b2c81627a8",
   "metadata": {},
   "source": [
    "***Display the first 5 rows*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920eba48-983f-4642-a67a-8fe5c3e8f4cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56636bd-8420-4315-a4e0-2b80a1321198",
   "metadata": {},
   "source": [
    "***Dataframe shape***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bdc4ee-55cf-421a-8c3e-c01cda0f401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, columns = sample_accepted_df.shape\n",
    "print(f'Dataframe rows: {rows}')\n",
    "print(f'Dataframe columns: {columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c7f0b4-be64-481e-b037-ce120f9a3468",
   "metadata": {},
   "source": [
    "***Dataframe info***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19999f-ad78-47e5-b0fc-58d1611b1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e0d141-e367-4544-ac05-ed512a73befb",
   "metadata": {},
   "source": [
    "Of the 151 columns, 113 are float64 and 38 are objects. The dataframe takes up approximatly 580 MB.\n",
    "Note:\n",
    "- The numeric columns are all float64 and the object columns. These columns can be optimized later to save memory space and decrease computation time by changing the datatypes.\n",
    "- There is no datetime column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1c760-6652-45d4-943c-ab25d0d6e3ac",
   "metadata": {},
   "source": [
    "***Describe Dataframe***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c918cb-205c-4c27-bffb-d97ae2cfea68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef8472-ba68-40fd-a8f8-51ca5f361f41",
   "metadata": {},
   "source": [
    "Some key points:\n",
    "\n",
    "- Loan Amount\n",
    "  \n",
    "    - Average Loan Amount is ~ 15,000 USD with a standard deviation of 9240 USD, having a max of 40,000 USD and minimum of 500 USD. This follows LendingClubs  policies for minimum and maximum loan amounts.\n",
    "\n",
    "- Funded amount\n",
    "    - Nearly identical to the loan amount\n",
    "\n",
    "- Funded amount by investors\n",
    "    - Very similar to the  funded amount\n",
    "\n",
    "- Interest Rate\n",
    "    - The interest rates are quite high. An average of 13%, with a minimum of 5.3% and a maximum of 31%.\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a5a990-33e3-40be-a84c-f19f4a3370a1",
   "metadata": {},
   "source": [
    "***Null Values***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a5e843-b569-4752-896e-7cd3829839c8",
   "metadata": {},
   "source": [
    "Some rows are fully NaN values, aside from the id. This will cause issues when we try to inspect each column later. So we will drop `id` and the NaN rows, along with any other irrelevant columns including:  \n",
    "- member_id\n",
    "- url for the loan\n",
    "- LC policy code\n",
    "- title (information is already found under purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51389a0c-e59b-4fac-8fc5-e6e07b2d3666",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns=['id', 'member_id', 'url', 'policy_code', 'title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f4508-eb08-4980-8053-800c968c6674",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows = sample_accepted_df.isnull().all(axis=1).sum()\n",
    "print(f\"Number of Null rows: {null_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde43a87-7961-4f4e-a616-ff5f10ca104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows that are all Nan\n",
    "sample_accepted_df.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de04222e-f762-48ed-85db-21c570a6cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows = sample_accepted_df.isnull().all(axis=1).sum()\n",
    "print(f\"Number of Null rows: {null_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb7c08-1e26-4bdd-a78e-79e679ee9517",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea0b31-7071-4b24-acf6-b8ba08c80ab2",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6facfa-7c85-4248-80f9-73526181f28d",
   "metadata": {},
   "source": [
    "### Feature Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1756e8a9-5175-4722-9cb7-05ac6fb29350",
   "metadata": {},
   "source": [
    "We will exclude any leaky features, non relevant features and any features that were not present in the original loan application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c4573a-8b2f-4bb2-ba4c-70924ca8d8e6",
   "metadata": {},
   "source": [
    "#### ***Irrelevant columns***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594259a2-bb55-4e9f-83c9-2fec98d87d57",
   "metadata": {},
   "source": [
    "***Secondary Applicants Information***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c2bd4-a2dc-41b0-bf73-d2e83882e390",
   "metadata": {},
   "source": [
    "The columns for the secondary applicant are largely nulls, so we will drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e993a-c13a-4102-b9a2-878f2da59f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sample_accepted_df.isnull().sum()/sample_accepted_df.shape[0]*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadcd1a5-d253-433a-80c7-6dadf5c02e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['application_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af11918-5123-4012-a7e2-fa39db75c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the loans where revol_bal_joint is not null\n",
    "rows_to_remove = sample_accepted_df.loc[sample_accepted_df['application_type'] == 'Joint App'].index\n",
    "\n",
    "# Drop the loans\n",
    "sample_accepted_df.drop(rows_to_remove, inplace=True)\n",
    "\n",
    "sample_accepted_df.drop(columns = ['revol_bal_joint', 'sec_app_fico_range_low', \n",
    "                                   'sec_app_fico_range_high', 'sec_app_earliest_cr_line',\n",
    "                                   'sec_app_inq_last_6mths', 'sec_app_mort_acc',\n",
    "                                   'sec_app_open_acc', 'sec_app_revol_util', \n",
    "                                   'sec_app_open_act_il', 'sec_app_num_rev_accts', \n",
    "                                   'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med',\n",
    "                                   'sec_app_mths_since_last_major_derog',\n",
    "                                   'verification_status_joint', 'dti_joint',\n",
    "                                   'annual_inc_joint', 'application_type'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c172e55a-4537-4c77-b59a-2b7099665e37",
   "metadata": {},
   "source": [
    "***Loan Grade***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39076c9-ca6d-449f-9ac1-b633254bd7a1",
   "metadata": {},
   "source": [
    "We will also drop the credit rating assigned by Lendingclub as we want to do our own assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b76157e-6356-476a-bf42-4cb9e23d7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns=['grade','sub_grade'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcb2528-04a2-4bf8-9e8b-35684f218961",
   "metadata": {},
   "source": [
    "***Hardship Loans***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84627eb9-a026-45f0-9c79-deed21f04a60",
   "metadata": {},
   "source": [
    "Hardship loans make up a very small proportion of the dataset, and add 15 columns of complexity. We will drop these columns and loans if they exist in our dataset, and limit our analysis to non hardship loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7494db37-7e22-42bf-b9d3-b239b3a8b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch the value counts for the for the hardships flags\n",
    "hardships = sample_accepted_df['hardship_flag'].value_counts()\n",
    "display(hardships)\n",
    "\n",
    "#if there are loans with the yes hardship flag\n",
    "if 'Y' in hardships:\n",
    "    #get the count of hardship loans\n",
    "    yes_hardship_count = hardships.iloc[1]\n",
    "    print(f'The hardship loans represent only {(yes_hardship_count/sample_accepted_df.shape[0])*100}% of the dataset')\n",
    "\n",
    "    #get the index of the hardship loans\n",
    "    rows_to_remove = sample_accepted_df.loc[sample_accepted_df['hardship_flag'] == 'Y'].index\n",
    "\n",
    "    #drop the loans\n",
    "    sample_accepted_df.drop(rows_to_remove, inplace=True)\n",
    "\n",
    "    #check the rows have been dropped\n",
    "    assert sample_accepted_df['hardship_flag'].value_counts().shape[0] == 1\n",
    "    print('Hardship loans and associated columns have been dropped')\n",
    "\n",
    "else:\n",
    "    print('There are no hardship loans.')\n",
    "    \n",
    "columns_to_drop = ['hardship_flag', 'hardship_type',\n",
    "                        'hardship_reason', 'hardship_status',\n",
    "                        'hardship_amount', 'hardship_start_date',\n",
    "                        'hardship_end_date', 'deferral_term',\n",
    "                        'hardship_length', 'hardship_dpd',\n",
    "                        'hardship_loan_status', 'payment_plan_start_date',\n",
    "                        'orig_projected_additional_accrued_interest', 'hardship_payoff_balance_amount',\n",
    "                        'hardship_last_payment_amount']\n",
    "\n",
    "sample_accepted_df.drop(columns = columns_to_drop, inplace=True)\n",
    "print('Hardship columns have been dropped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da596ba-5ab4-404b-bbec-17512fb74d52",
   "metadata": {},
   "source": [
    "***Employee Title***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d66d8a-f335-4730-a3d8-3e250c90b8e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted_df['emp_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd6fbc-6581-4e0b-acc7-67e0033e9df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_accepted_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47852c1-265e-4d71-a24d-b3ea23a3613d",
   "metadata": {},
   "source": [
    "There are too many unique Employee titles to attempt any sort of grouping or encoding for now. Possibly in the future we could use NLP or an external API to group the Employee Title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a35c2-a353-42c8-97d7-a8c37ac68ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns = 'emp_title', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b591cd9-2d31-4f79-b4b2-3a37037549e6",
   "metadata": {},
   "source": [
    "***Loan Status***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381b39a4-194a-44af-b8f3-4b60d6306067",
   "metadata": {},
   "source": [
    "Any current loans have already been dropped when reading in the data. We can now finish grouping the completed loans.\n",
    "\n",
    "More information on the loan status's can be found here:  \n",
    "https://www.lendingclub.com/help/investing-faq/what-do-the-different-note-statuses-mean  \n",
    "https://www.fintechnexus.com/policy-code-2-loans-lending-club/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd57575f-8b7f-4bba-8996-93410ab022cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea29433-eb73-4a00-9966-27eda0b151fb",
   "metadata": {},
   "source": [
    "The \"Does not meet the credit policy\" means when the loans were made under a different credit card policy, that does not meet the current policy. This has affect on the loans themselves, so they can be grouped with their counter parts. Charged off and Defaulted can also been grouped together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce01bb-eae2-4b0c-a737-c6d5547c0713",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_mapping = {\n",
    "    \"Fully Paid\": \"Fully Paid\",\n",
    "    \"Does not meet the credit policy. Status:Fully Paid\": \"Fully Paid\",\n",
    "    \"Does not meet the credit policy. Status:Charged Off\": \"Charged Off/Default\",\n",
    "    \"Charged Off\": \"Charged Off/Default\",\n",
    "    \"Default\": \"Charged Off/Default\",\n",
    "}\n",
    "\n",
    "#map the loans\n",
    "sample_accepted_df['loan_status'] = sample_accepted_df['loan_status'].map(status_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0796ad-1907-4689-ad57-822aba616c1f",
   "metadata": {},
   "source": [
    "Check the mapping has worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9249f16-102a-4d66-8b47-9bbef101b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deef39a-1730-461e-ac46-076d026c37b0",
   "metadata": {},
   "source": [
    "The mapping was successful, we are not left with only successful and failed loans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53532cc-5ad0-460d-9429-f2eea8f2a935",
   "metadata": {},
   "source": [
    "***State / Zip Code***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ef163c-161d-4062-b812-5790db588395",
   "metadata": {},
   "source": [
    "We have 2 geographical features. We will drop both of them for now as they will add too much complexity to the model. However, in the future we can perhaps use a 3rd party api and introduce mean or median income data by region, allowing us to capture some of that geographical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721aaa62-41f5-4a0b-ad1a-f8d1f06dcbaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(sample_accepted_df['addr_state'].value_counts())\n",
    "print('-'*20)\n",
    "display(sample_accepted_df['zip_code'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87b672-318a-4f22-84d9-f10d7c4a2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns = ['zip_code', 'addr_state'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c2c97-daae-4c32-a4e7-e738fd265ea2",
   "metadata": {},
   "source": [
    "***Fico scores***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f7299e-694c-4e1c-b2bb-3e3cced3edd8",
   "metadata": {},
   "source": [
    "We can drop the fico scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c103a7c-1cd5-43d5-88db-7cb95fbdf179",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns = ['last_fico_range_high', 'last_fico_range_low',\n",
    "                                   'fico_range_low', 'fico_range_high'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a1ae78-5f90-4d17-bb8f-e0cd9a6123e4",
   "metadata": {},
   "source": [
    "***Description***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb13b4-0041-4f29-ad9c-b9b076825b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(sample_accepted_df['desc'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6802c9-e66b-4855-b6c2-70a054420f34",
   "metadata": {},
   "source": [
    "There are too many unique descriptions to create dummy variables. We can drop this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3584d-db90-4053-8aaf-e0f79a1b150a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns = ['desc'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f06b3-0a74-430b-b90d-7ce674429b2f",
   "metadata": {},
   "source": [
    "#### Leaky columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89a4b8a-061c-4356-b5d9-233338145429",
   "metadata": {},
   "source": [
    "We will remove any columns that can leak the outcome of the application ie, any data the originates after a loan has been funded or rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f5b947-0c23-4524-b813-8ca4514989bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac06b12-2fa8-4fc0-891e-14182c26a7f3",
   "metadata": {},
   "source": [
    "We can remove any columns that:  \n",
    "- describe payments made toward the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779075ae-976b-43a6-89be-ff0f6e580a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns = ['total_pymnt', 'total_rec_prncp',\n",
    "                       'total_rec_int', 'total_rec_late_fee',\n",
    "                       'recoveries', 'collection_recovery_fee',\n",
    "                       'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'total_pymnt_inv', \n",
    "                                   'collections_12_mths_ex_med', 'collection_recovery_fee',\n",
    "                                  'mths_since_last_delinq', 'mths_since_last_record', 'mths_since_last_major_derog', 'initial_list_status'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feccfa3b-249d-43c3-adb2-4ad0e24650eb",
   "metadata": {},
   "source": [
    "- loan attributes post acceptance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac62cd-af28-4d45-a673-0f5d127290be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns=['out_prncp', 'out_prncp_inv',\n",
    "                                 'pymnt_plan',\n",
    "                                'acc_now_delinq', 'last_credit_pull_d',\n",
    "                                'debt_settlement_flag_date', 'settlement_term',\n",
    "                                 'total_il_high_credit_limit', 'total_bc_limit',\n",
    "                                 'num_tl_120dpd_2m', 'num_tl_30dpd', 'disbursement_method',\n",
    "                                ], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceafa17-fb79-4f12-aacb-b73abdfd4faf",
   "metadata": {},
   "source": [
    "- any settlement information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cbf977-603d-4ff1-bd7a-867cb70dc9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns=['debt_settlement_flag', 'settlement_status',\n",
    "                                 'settlement_date', 'settlement_amount',\n",
    "                                 'settlement_percentage'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdaca44-9d64-43e0-a42e-94972e2567c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df46cbb-0d55-4bb7-9925-dd3c0e0f0216",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ea73c-ad5a-4827-b3a6-5c18498e30f8",
   "metadata": {},
   "source": [
    "***Term***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba074c4-bd8b-4c18-abd1-f8200ebafda0",
   "metadata": {},
   "source": [
    "Convert from str to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a66dd-222b-442e-8bb0-7ca63d8b805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['term'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a67d0a0-bdfc-4bf2-80fb-f5fdd6b131f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the \"months\" text and convert to int\n",
    "sample_accepted_df['term'] = sample_accepted_df['term'].str.extract('(\\d+)').astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289dedea-cff8-42ed-bad0-dae62d391ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['term'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223a8bdf-c1b7-468c-b7cb-3346b7753fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903bacd-1b00-4453-ab93-eeb65d5b3824",
   "metadata": {},
   "source": [
    "***Emp_Length***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860af3aa-beee-42f7-8d1f-09b323140575",
   "metadata": {},
   "source": [
    "We will map greater than 10 years to 10, less than 1 year to 0.5 as to differentiate it between 1 and 0, preserving that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c8693-33af-445a-b055-2cc59e367c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['emp_length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b62e80d-722d-460f-b8ad-8979807408ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['emp_length'].fillna(value='0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc877d-e9b8-4927-b8e5-38db67296a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['emp_length'] = sample_accepted_df['emp_length'].apply(map_emp_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f1b00-2108-45ab-980c-96517af37774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted_df['emp_length'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f6f87f-24a1-45aa-bc80-993925334daa",
   "metadata": {},
   "source": [
    "### Dataframe-Null-Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5004f2e1-638d-4833-8213-63dbca23b3a6",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee32b34-8344-4d72-bd89-b00b86e4b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b3b334-ed17-47b0-994d-e45acd3d2e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted_df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd676544-e182-4021-bcb9-e965bc90cfc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(sample_accepted_df.isnull().sum()/sample_accepted_df.shape[0]*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d922521c-af00-4ce6-ba7b-bbfc4593eec1",
   "metadata": {},
   "source": [
    "Note how there seems to be groupings of nulls. We will explore these groupings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8087ca7a-d895-4bea-9dda-8159c36deb7c",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c81fb5-6497-4ad6-b4a9-18854a4ed8d7",
   "metadata": {},
   "source": [
    "***Explore the groupings of nulls***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e64fb11-98ed-472e-928d-f26230ba50b1",
   "metadata": {},
   "source": [
    "***Debt to Income***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667eb5fc-b47a-44bb-8a65-4c8735f2f650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted_df['dti'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e2f0f-a07d-4d83-90c1-54ff5e2b4bb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "null_rows = sample_accepted_df[sample_accepted_df['dti'].isnull()]\n",
    "print('Number of null rows in dti: ', sample_accepted_df['dti'].isnull().sum())\n",
    "display(null_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7379a-d5a5-4948-9280-f63f10aac01c",
   "metadata": {},
   "source": [
    "We can see that if there is no reported income, then dti is NaN as you can't divide by 0. This is a key metric used in evaluating a borrowers creditworthiness. We will fill it with a large dummy variable (10000) to preserve some of the information the ratio is trying to convey; in this case if a borrower does not have any income. We could also drop these rows as well as there are only a few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573a3bb-0f3e-4459-a3bd-6660c16fa6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['dti'].fillna(value=10000,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69de2f6-587b-452c-9e69-0509edc0a615",
   "metadata": {},
   "source": [
    "Check the column has been updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c17b0-1fcc-411d-adc1-47bedfc645fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['dti'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d940c0d-c570-4aa7-b200-6dc245e10d5b",
   "metadata": {},
   "source": [
    "***inq_last_12m***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9615a5-2e48-493f-8b4d-cfe7b0c79320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted_df['inq_last_12m'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa825d-8153-49f8-aa2f-dd4fdc3d998b",
   "metadata": {},
   "source": [
    "***open_acc_6m***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596156eb-b898-41e1-9105-4a0bf5f3314a",
   "metadata": {},
   "source": [
    "We can see from the nulls values that there is a grouping of nulls that make up approximatly 0.48% of the dataset. We will explore these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9460d36-b0b1-4b2d-ad30-34a9dd3170eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['open_acc_6m'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b48e8d5-5897-4662-80ae-a25581e73efd",
   "metadata": {},
   "source": [
    "https://www.fintechnexus.com/lending-club-adds-15-new-fields-and-folio-introduces-a-true-secondary-market-api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b774a44e-186c-4779-a262-0f82bae69d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns= ['max_bal_bc','open_rv_24m',\n",
    "                                  'open_rv_12m','inq_fi',\n",
    "                                  'total_bal_il','inq_last_12m',\n",
    "                                  'open_il_24m','open_il_12m',\n",
    "                                  'open_act_il','total_cu_tl','open_acc_6m'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fcc5ec-b3f3-4a79-a753-42a97658c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2f1924-2fd7-4568-9263-91b02458bf4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ea103-d8aa-4168-8941-3be4db9b027f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(sample_accepted_df.isnull().sum()/sample_accepted_df.shape[0]*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1e112-ea9c-41b5-835f-f06e198a1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['mths_since_recent_bc_dlq','mths_since_recent_revol_delinq',\n",
    "                   'il_util','mths_since_recent_inq','mths_since_rcnt_il',\n",
    "                   'mo_sin_old_il_acct','bc_util',\n",
    "                   'bc_open_to_buy','percent_bc_gt_75',\n",
    "                   'mths_since_recent_bc','all_util','revol_util']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d009674-167c-4d95-97fb-6cb3aede51a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns = columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb955c9-b3ec-4971-8362-1abbbe37dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ffb2e1-2fb5-4109-925d-02aa3da86fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(sample_accepted_df.isnull().sum()/sample_accepted_df.shape[0]*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e518b6b-a54b-4f6f-9bd4-1d6d6fa85b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.dropna(subset=['annual_inc', 'total_acc', \n",
    "                                  'tax_liens', 'chargeoff_within_12_mths', \n",
    "                                  'pub_rec_bankruptcies', 'total_bal_ex_mort',\n",
    "                                  'tot_hi_cred_lim', 'avg_cur_bal', 'pct_tl_nvr_dlq'\n",
    "                                 ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0993ffb-e016-42cf-ba73-0dd92718d1ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(sample_accepted_df.isnull().sum()/sample_accepted_df.shape[0]*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fc5270-5fff-4c12-96fa-67dba4fda1b6",
   "metadata": {},
   "source": [
    "### Dataframe Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01727d-1e3d-4bf5-b2fa-7340bfb5e0f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(sample_accepted_df.info())\n",
    "#sample_accepted_df = pdc.downcast(sample_accepted_df)\n",
    "#print(sample_accepted_df.info())\n",
    "# Infer minimum schema for DataFrame.\n",
    "#schema = pdc.infer_schema(sample_accepted_df)\n",
    "#print(schema)\n",
    "#sample_accepted_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8771be-5e39-4679-9789-c46bd8391e6a",
   "metadata": {},
   "source": [
    "TODO: Optimize column datatypes to reduce code runtime and increase memory efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c14064-1071-406e-8555-5a3100f3c7c2",
   "metadata": {},
   "source": [
    "### Export Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9d27d-4a37-4666-be89-a9d599cde864",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_destination = Path('../Data/Lending_club/Cleaned')\n",
    "sample_accepted_df.to_parquet(export_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca58ad45-66a0-4101-a0e3-ac89b8829abd",
   "metadata": {},
   "source": [
    "### Feature-Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29676f65-7084-4169-80cd-5da49ae0719f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "['loan_amnt',\r\n",
    " 'funded_amnt',\r\n",
    " 'funded_amnt_inv',\r\n",
    " 'term',\r\n",
    " 'int_rate',\r\n",
    " 'installment',\r\n",
    " 'grade',\r\n",
    " 'sub_grade',\r\n",
    " 'emp_title',\r\n",
    " 'emp_length',\r\n",
    " 'home_ownership',\r\n",
    " 'annual_inc',\r\n",
    " 'verification_status',\r\n",
    " 'loan_status',\r\n",
    " 'purpose',\r\n",
    " 'addr_state',\r\n",
    " 'dti',\r\n",
    " 'delinq_2yrs',\r\n",
    " 'earliest_cr_line',\r\n",
    " 'fico_range_low',\r\n",
    " 'fico_range_high',\r\n",
    " 'inq_last_6mths',\r\n",
    " 'open_acc',\r\n",
    " 'pub_rec',\r\n",
    " 'revol_bal',\r\n",
    " 'revol_util',\r\n",
    " 'total_acc',\r\n",
    " 'initial_list_status',\r\n",
    " 'application_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e52df29-ef46-4271-bc0e-e29edce560f0",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a935c1-af40-4292-9db5-1b7d3b383943",
   "metadata": {},
   "source": [
    "### Resources used:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9042de83-cf0d-41c1-b9b6-6e53a25bf0fa",
   "metadata": {},
   "source": [
    "- https://stackoverflow.com/questions/51325601/how-to-stop-my-pandas-data-table-from-being-truncated-when-printed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loans_capstone",
   "language": "python",
   "name": "loans_capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
