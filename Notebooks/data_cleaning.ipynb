{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9533d898-2c8f-4b1a-a1fe-8dcf42bf4abf",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Function for remove a set of columns / rows and check theyve been removed by returning bool\n",
    "* Can do PCA but mostly note for financial loan data as its very hard to be explainable. Can maybe save it for later\n",
    "* Can do stratify Y\n",
    "* Write a helper func to display the data dict\n",
    "* verify drop hardship loans works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a87e7-3f0f-49cd-bf5c-740bc94a1a17",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a19a03-c85e-4502-b298-c85101ef9b6e",
   "metadata": {},
   "source": [
    "## Date: OCT 10, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f4e8ea",
   "metadata": {},
   "source": [
    "-- ------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1715de5e-0908-4ff3-82ce-246ed69273ca",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7606bb8-f8a4-4c60-85ef-858832c9e883",
   "metadata": {},
   "source": [
    "This notebook cleans the data for the lending club accepted loans, then exports the data as a parquet file. Due to the size of the dataset, the csv is read in chunks, with a random sample taken from each each chunk. Only fully paid and charged off / defaulted loans are sampled as current loans hold no value in classifying the target variable. Those samples are merged and will become the working dataset for the duration of the project. After unnecessary and leaky features are removed, features are formatted and null values dealt with. Finally the dataframe is size is optimized and exported  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1701fc-f92e-4bd9-a8f3-b9c891eadf34",
   "metadata": {},
   "source": [
    "### Table-of-contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bbe9b1-8cfd-4215-b9ca-6ec5d9a2b7e7",
   "metadata": {},
   "source": [
    "\n",
    "1. [Introduction](#Introduction)\n",
    "   - [Table-of-contents](#Table-of-contents)\n",
    "   - [Import-Librarys](#Import-Librarys)\n",
    "   - [Data Dictionary](#Data-Dictionary)\n",
    "   - [Define-Functions](#Define-Functions)\n",
    "   - [Load in the data](#Load-the-data)\n",
    "3. [Data Cleaning](#Data-Cleaning)\n",
    "   - [Initial Exploration](#Initial-Exploration)\n",
    "   - [Feature Pruning](#Feature-Pruning)\n",
    "   - [Explore Columns to drop](#Explore-Columns-to-drop)\n",
    "   - [Dataframe Null Values](#Dataframe-Null-Values)\n",
    "4. [Dataframe optimization](#Dataframe-optimization)\n",
    "5. [Exploratory-Data-Analysiss](Exploratory-Data-Analysis)\n",
    "6. [Feature Engineering](#Feature-Engineering)\n",
    "7. . [Conclusion](#Conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9252c44",
   "metadata": {},
   "source": [
    "### Import-Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97841a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas-downcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890b8ae-7ed0-4e0e-88a8-d33a33f5ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run helpers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from helpers import full_display\n",
    "#import pdcast as pdc\n",
    "#import missingno as msno\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17654b3a-269f-4d42-a4c3-b10a8873d67a",
   "metadata": {},
   "source": [
    "### Data-Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d7734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pathlib is used to ensure compatibility across operating systems\n",
    "try:\n",
    "    data_destination = Path('../Data/Lending_club/Lending Club Data Dictionary Approved.csv')\n",
    "    dict_df = pd.read_csv(data_destination, encoding='ISO-8859-1')\n",
    "    display(dict_df.iloc[:,0:2])\n",
    "except FileNotFoundError as e:\n",
    "    print(e.args[1])\n",
    "    print('Check file location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c720f-9f8a-490c-9bcc-5c84aa28e660",
   "metadata": {},
   "source": [
    "#### Define-Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf7abd-8cce-4099-b670-73456af6d1a8",
   "metadata": {},
   "source": [
    "When initially loading in the dataset, Pandas raised a DtypeWarning over mixed datatypes within various columns. Setting low_memory = False while breaking the CSV into chunks allows Pandas to load an entire chunk before guessing the data types. When the script to scrape the data dictionary is finished, the data dict can then be passed in instead of relying on pandas. The mixed_data_types function is stilled called as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e3869-47e5-4e04-b89b-ebbe8a4da053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_data_types(df:pd.DataFrame) -> bool:\n",
    "    '''\n",
    "    Takes in a dataframe and checks for columns with mixed data types\n",
    "    If none are found return False, else True\n",
    "    \n",
    "    :param df: The dataframe to be checked\n",
    "    :type df: obj\n",
    "    :return bool: True if found, false if none were found\n",
    "    :type return: bool\n",
    "    '''\n",
    "    \n",
    "    #loop through each column\n",
    "    for column in df:\n",
    "\n",
    "        #filter outint datatypes coming from Nan and get unique data types\n",
    "        unique_types = df[column].dropna(inplace=False).apply(type).unique()\n",
    "\n",
    "        #if there are more than 1 datatype in a column\n",
    "        if unique_types.size > 1:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca6832-dcef-4a75-8fa7-60116adbc3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_column(df:pd.DataFrame):\n",
    "    '''\n",
    "    Takes in a dataframe and returns the dataframe with the smallest datatype for each column\n",
    "    Example int64 -> int32\n",
    "    '''\n",
    "    datatypes = df.dtypes.unique()\n",
    "    for column in df:\n",
    "        if df[col].dtype == 'int':\n",
    "            pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a6fb5-5a8d-421a-84f1-838cd93fac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_row(df):\n",
    "    '''\n",
    "    takes in some rows and then drops those rows. Checks rows have been dropped\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b1603-308a-4ddb-9766-594feac1245a",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a42820-7bc4-4790-81d5-ef808754cd70",
   "metadata": {},
   "source": [
    "Due to the size of the dataset, it is read in chunks. After each chunk is read and checked for mixed data types, it is randomly sampled and then placed within a list. Only fully paid and /defaulted and charged off loans are taken, as current loans including late or in grace period loans do not hold any value in target variable prediction. This is done when loading in the data otherwise it becomes too large for memory. The different samples are then combined into a single sample representative of the whole dataset. EDA will be performed on this single sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d90c2-bd23-4f8a-9a9e-c3ce8acbaab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 5*100000\n",
    "sample_size =  100000\n",
    "random_state = 11\n",
    "\n",
    "assert sample_size < chunk_size, f\"Cannot take a sample of {sample_size} rows out of {chunk_size} rows\"\n",
    "\n",
    "print(f'Chunk size: {chunk_size} rows')\n",
    "print(f'Rows to be sampled: {sample_size} rows')\n",
    "\n",
    "\n",
    "sampled_dataframes = []\n",
    "try:\n",
    "    data_destination = Path('../Data/Lending_club/accepted_2007_to_2018Q4.csv')\n",
    "\n",
    "    #split the csv into chunks and iterate over each chunk\n",
    "    with pd.read_csv(data_destination, chunksize=chunk_size, low_memory = False) as reader:\n",
    "        for count,chunk in enumerate(reader):\n",
    "            \n",
    "            if mixed_data_types(df=chunk) == True:\n",
    "                raise Exception(\"Mixed data types found\")\n",
    "\n",
    "            #define a list that includes only finished loan statuses\n",
    "            finished_loan_status = ['Fully Paid',\n",
    "                                    'Charged Off',\n",
    "                                    'Does not meet the credit policy. Status:Fully Paid',\n",
    "                                    'Does not meet the credit policy. Status:Charged Off',\n",
    "                                    'Default']\n",
    "            \n",
    "            #filter the dataframe for loans that are finished or null\n",
    "            filtered_chunk = chunk.loc[chunk['loan_status'].isin(finished_loan_status) | chunk['loan_status'].isnull()]\n",
    "\n",
    "            #sample the filtered df and append to list\n",
    "            sampled_df = filtered_chunk.sample(n=sample_size, random_state=random_state)\n",
    "            sampled_dataframes.append(sampled_df)\n",
    "            \n",
    "            print(f\"{count} sampled dataframe shape: {sampled_df.shape}\")\n",
    "        print('Finished')\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e.args[1])\n",
    "    print('Check file name and location')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e.args[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf972fc-423c-4d4e-86fa-af16729ef0b3",
   "metadata": {},
   "source": [
    "There are no duplicate datatypes within any columns. The random samples can be combined into a single sample dataframe. This sample will be used as the working dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd48046-7d83-4aa7-86b1-66d7349cb708",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df = pd.concat(sampled_dataframes, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee15a8a-69e1-4da0-9062-fe55b7fea232",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08d900-4c61-4f28-a187-b678483e509b",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f56533c-c67d-44e3-a7ad-45481efa64bc",
   "metadata": {},
   "source": [
    "### Initial Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec421c-5836-454e-b624-d2b2c81627a8",
   "metadata": {},
   "source": [
    "***Display the first 5 rows*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920eba48-983f-4642-a67a-8fe5c3e8f4cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56636bd-8420-4315-a4e0-2b80a1321198",
   "metadata": {},
   "source": [
    "***Dataframe shape***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bdc4ee-55cf-421a-8c3e-c01cda0f401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, columns = sample_accepted_df.shape\n",
    "print(f'Dataframe rows: {rows}')\n",
    "print(f'Dataframe columns: {columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c7f0b4-be64-481e-b037-ce120f9a3468",
   "metadata": {},
   "source": [
    "***Dataframe info***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19999f-ad78-47e5-b0fc-58d1611b1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e0d141-e367-4544-ac05-ed512a73befb",
   "metadata": {},
   "source": [
    "Of the 151 columns, 113 are float64 and 38 are objects. The dataframe takes up approximatly 580 MB.\n",
    "Note:\n",
    "- The numeric columns are all float64 and the object columns. These columns can be optimized later to save memory space and decrease computation time by changing the datatypes.\n",
    "- There is no datetime column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1c760-6652-45d4-943c-ab25d0d6e3ac",
   "metadata": {},
   "source": [
    "***Describe Dataframe***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c918cb-205c-4c27-bffb-d97ae2cfea68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef8472-ba68-40fd-a8f8-51ca5f361f41",
   "metadata": {},
   "source": [
    "Some key points:\n",
    "\n",
    "- Loan Amount\n",
    "  \n",
    "    - Average Loan Amount is ~ 15,000 USD with a standard deviation of 9240 USD, having a max of 40,000 USD and minimum of 500 USD. This follows LendingClubs  policies for minimum and maximum loan amounts.\n",
    "\n",
    "- Funded amount\n",
    "    - Nearly identical to the loan amount\n",
    "\n",
    "- Funded amount by investors\n",
    "    - Very similar to the  funded amount\n",
    "\n",
    "- Interest Rate\n",
    "    - The interest rates are quite high. An average of 13%, with a minimum of 5.3% and a maximum of 31%.\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6facfa-7c85-4248-80f9-73526181f28d",
   "metadata": {},
   "source": [
    "### Feature Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1756e8a9-5175-4722-9cb7-05ac6fb29350",
   "metadata": {},
   "source": [
    "We will exclude any leaky features, non relevant features and any features that were not present in the original loan application, focusing first on dropping irrelevant columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcb2528-04a2-4bf8-9e8b-35684f218961",
   "metadata": {},
   "source": [
    "***Hardship Loans***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84627eb9-a026-45f0-9c79-deed21f04a60",
   "metadata": {},
   "source": [
    "Hardship loans make up a very small proportion of the dataset, and add 15 columns of complexity. We will drop these columns and loans if they exist in our dataset, and limit our analysis to non hardship loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7494db37-7e22-42bf-b9d3-b239b3a8b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch the value counts for the for the hardships flags\n",
    "hardships = sample_accepted_df['hardship_flag'].value_counts()\n",
    "display(hardships)\n",
    "\n",
    "#if there are loans with the yes hardship flag\n",
    "if 'Y' in hardships:\n",
    "    #get the count of hardship loans\n",
    "    yes_hardship_count = hardships.iloc[1]\n",
    "    print(f'The hardship loans represent only {(yes_hardship_count/sample_accepted_df.shape[0])*100}% of the dataset')\n",
    "\n",
    "    #get the index of the hardship loans\n",
    "    rows_to_remove = sample_accepted_df.loc[sample_accepted_df['hardship_flag'] == 'Y'].index\n",
    "\n",
    "    #drop the loans\n",
    "    sample_accepted_df.drop(rows_to_remove, inplace=True)\n",
    "\n",
    "    #check the rows have been dropped\n",
    "    assert sample_accepted_df['hardship_flag'].value_counts().shape[0] == 1\n",
    "    print('Hardship loans and associated columns have been dropped')\n",
    "\n",
    "else:\n",
    "    print('There are no hardship loans.')\n",
    "    \n",
    "columns_to_drop = ['hardship_flag', 'hardship_type',\n",
    "                        'hardship_reason', 'hardship_status',\n",
    "                        'hardship_amount', 'hardship_start_date',\n",
    "                        'hardship_end_date', 'deferral_term',\n",
    "                        'hardship_length', 'hardship_dpd',\n",
    "                        'hardship_loan_status', 'payment_plan_start_date',\n",
    "                        'orig_projected_additional_accrued_interest', 'hardship_payoff_balance_amount',\n",
    "                        'hardship_last_payment_amount']\n",
    "sample_accepted_df.drop(columns = columns_to_drop)\n",
    "print('Hardship columns have been dropped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da596ba-5ab4-404b-bbec-17512fb74d52",
   "metadata": {},
   "source": [
    "***Employee Title***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d66d8a-f335-4730-a3d8-3e250c90b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['emp_title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47852c1-265e-4d71-a24d-b3ea23a3613d",
   "metadata": {},
   "source": [
    "There are too many unique Employee titles to attempt any sort of grouping or encoding for now. Possibly in the future we could use NLP or an external API to group the Employee Title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a35c2-a353-42c8-97d7-a8c37ac68ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns = 'emp_title', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b591cd9-2d31-4f79-b4b2-3a37037549e6",
   "metadata": {},
   "source": [
    "***Loan Status***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381b39a4-194a-44af-b8f3-4b60d6306067",
   "metadata": {},
   "source": [
    "Any current loans have already been dropped when reading in the data. We can now finish grouping the completed loans.\n",
    "\n",
    "More information on the loan status's can be found here:  \n",
    "https://www.lendingclub.com/help/investing-faq/what-do-the-different-note-statuses-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd57575f-8b7f-4bba-8996-93410ab022cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea29433-eb73-4a00-9966-27eda0b151fb",
   "metadata": {},
   "source": [
    "The \"Does not meet the credit policy\" means when the loans were made under a different credit card policy, that does not meet the current policy. This has affect on the loans themselves, so they can be grouped with their counter parts. Charged off and Defaulted can also been grouped together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce01bb-eae2-4b0c-a737-c6d5547c0713",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_mapping = {\n",
    "    \"Fully Paid\": \"Fully Paid\",\n",
    "    \"Does not meet the credit policy. Status:Fully Paid\": \"Fully Paid\",\n",
    "    \"Does not meet the credit policy. Status:Charged Off\": \"Charged Off/Default\",\n",
    "    \"Charged Off\": \"Charged Off/Default\",\n",
    "    \"Default\": \"Charged Off/Default\",\n",
    "}\n",
    "\n",
    "#map the loans\n",
    "sample_accepted_df['loan_status'] = sample_accepted_df['loan_status'].map(status_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0796ad-1907-4689-ad57-822aba616c1f",
   "metadata": {},
   "source": [
    "Check the mapping has worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9249f16-102a-4d66-8b47-9bbef101b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deef39a-1730-461e-ac46-076d026c37b0",
   "metadata": {},
   "source": [
    "The mapping was successful, we are not left with only successful and failed loans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53532cc-5ad0-460d-9429-f2eea8f2a935",
   "metadata": {},
   "source": [
    "***State / Zip Code***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ef163c-161d-4062-b812-5790db588395",
   "metadata": {},
   "source": [
    "We have 2 geographical features. We will drop both of them for now as they will add too much complexity to the model. However, in the future we can perhaps use a 3rd party api and introduce mean or median income data by region, allowing us to capture some of that geographical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721aaa62-41f5-4a0b-ad1a-f8d1f06dcbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sample_accepted_df['addr_state'].value_counts())\n",
    "print('-'*20)\n",
    "display(sample_accepted_df['zip_code'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87b672-318a-4f22-84d9-f10d7c4a2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns = 'zip_code', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c2c97-daae-4c32-a4e7-e738fd265ea2",
   "metadata": {},
   "source": [
    "***Fico scores***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f7299e-694c-4e1c-b2bb-3e3cced3edd8",
   "metadata": {},
   "source": [
    "We can drop the fico scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c34224-3e0c-41b4-8223-1c4fcb77fc23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted_df['last_fico_range_high'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c103a7c-1cd5-43d5-88db-7cb95fbdf179",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns = ['last_fico_range_high','last_fico_range_low'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a1ae78-5f90-4d17-bb8f-e0cd9a6123e4",
   "metadata": {},
   "source": [
    "***Description***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb13b4-0041-4f29-ad9c-b9b076825b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sample_accepted_df['desc'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6802c9-e66b-4855-b6c2-70a054420f34",
   "metadata": {},
   "source": [
    "There are too many unique descriptions to create dummy variables. We can drop this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3584d-db90-4053-8aaf-e0f79a1b150a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns = ['desc'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f06b3-0a74-430b-b90d-7ce674429b2f",
   "metadata": {},
   "source": [
    "***Leaky columns***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f5b947-0c23-4524-b813-8ca4514989bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac06b12-2fa8-4fc0-891e-14182c26a7f3",
   "metadata": {},
   "source": [
    "We can remove any columns that:  \n",
    "- describe payments made toward the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779075ae-976b-43a6-89be-ff0f6e580a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.drop(columns = ['total_pymnt', 'total_rec_prncp',\n",
    "                       'total_rec_int', 'total_rec_late_fee',\n",
    "                       'recoveries', 'collection_recovery_fee',\n",
    "                       'last_pymnt_d', 'last_pymnt_amnt'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feccfa3b-249d-43c3-adb2-4ad0e24650eb",
   "metadata": {},
   "source": [
    "- loan attributes post acceptance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac62cd-af28-4d45-a673-0f5d127290be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5df46cbb-0d55-4bb7-9925-dd3c0e0f0216",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ea73c-ad5a-4827-b3a6-5c18498e30f8",
   "metadata": {},
   "source": [
    "***Term***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e404a-92d9-48ea-ace0-9a378bb655ac",
   "metadata": {},
   "source": [
    "***CONVERT TO JUST 36 AND 60 LIKE INSTRUCTOR SAID***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba074c4-bd8b-4c18-abd1-f8200ebafda0",
   "metadata": {},
   "source": [
    "Convert from str to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a66dd-222b-442e-8bb0-7ca63d8b805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['term'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c250d9-bd82-4deb-8bef-f7e31a48f7c9",
   "metadata": {},
   "source": [
    "Remove rows that leak from future ie features about the loan after it has been given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a67d0a0-bdfc-4bf2-80fb-f5fdd6b131f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7f6f87f-24a1-45aa-bc80-993925334daa",
   "metadata": {},
   "source": [
    "### Dataframe-Null-Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5004f2e1-638d-4833-8213-63dbca23b3a6",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee32b34-8344-4d72-bd89-b00b86e4b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b3b334-ed17-47b0-994d-e45acd3d2e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd676544-e182-4021-bcb9-e965bc90cfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.isnull().sum()/sample_accepted_df.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d922521c-af00-4ce6-ba7b-bbfc4593eec1",
   "metadata": {},
   "source": [
    "Note how there seems to be groupings of nulls. We will explore these groupings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2217f6df-e294-4082-a509-a2a83b651053",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55574196-5cb5-4caa-8b70-b28419605cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(sample_accepted_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a153c3-b041-4c79-b0d2-5a39f3cf20fd",
   "metadata": {},
   "source": [
    "We can drop columns that are linked to LendingClubs internal tracking of the loans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85414c63-05f4-4f03-a3cb-bb48e7a9c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop.extend(['member_id','url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8087ca7a-d895-4bea-9dda-8159c36deb7c",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c81fb5-6497-4ad6-b4a9-18854a4ed8d7",
   "metadata": {},
   "source": [
    "***Explore the groupings of nulls***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d63e86-ead8-4675-8a33-18c168e997a8",
   "metadata": {},
   "source": [
    "We will start with the smallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5f3dc-5bd1-4a45-b105-ed274eb6f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows = sample_accepted_df[sample_accepted_df['revol_bal'].isnull()]\n",
    "print('Number of null rows in revol_bal: ', sample_accepted_df['revol_bal'].isnull().sum())\n",
    "display(null_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d1009-92d5-4414-bce2-f13c74343836",
   "metadata": {},
   "source": [
    "we can remove these null entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4071e25b-8f6f-47ec-85c2-fba97799ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.dropna(subset=['revol_bal'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b17989f-2280-4fb2-bdef-98c42ac4a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['revol_bal'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf6b54-d877-43e7-920c-87ed9b74dc97",
   "metadata": {},
   "source": [
    "***Annual income***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594abdd-9dbb-45c8-8331-722355c4d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_row = sample_accepted_df[sample_accepted_df['annual_inc'].isnull()]\n",
    "null_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e400b7ea-49a4-405c-9d10-5162e9678416",
   "metadata": {},
   "source": [
    "***Why i removed the row***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d249135-3b90-456f-af8c-fda080bc0f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df.dropna(subset=['annual_inc'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a9078-545c-4031-b26d-873c915312d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accepted_df['annual_inc'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83692b87-d365-40ae-802a-8221d0635d22",
   "metadata": {},
   "source": [
    "Total acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702149c-0bfe-4549-a2bc-3dea387d6701",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_row = sample_accepted_df[sample_accepted_df['total_acc'].isnull()]\n",
    "null_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07c1d4d-bcb2-4f97-b03b-0fc442791ed6",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b429d-97f9-4c2c-b4a9-65b5dde3d78f",
   "metadata": {},
   "source": [
    "### Explore Columns to drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fc5270-5fff-4c12-96fa-67dba4fda1b6",
   "metadata": {},
   "source": [
    "### Dataframe-optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fbf0da-21f2-4b40-bd89-8b60a8ad5429",
   "metadata": {},
   "source": [
    "Since we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01727d-1e3d-4bf5-b2fa-7340bfb5e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_accepted_df.info())\n",
    "sample_accepted_df = pdc.downcast(sample_accepted_df)\n",
    "print(sample_accepted_df.info())\n",
    "# Infer minimum schema for DataFrame.\n",
    "schema = pdc.infer_schema(sample_accepted_df)\n",
    "print(schema)\n",
    "sample_accepted_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8771be-5e39-4679-9789-c46bd8391e6a",
   "metadata": {},
   "source": [
    "TODO: Optimize column datatypes to reduce code runtime and increase memory efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96328d7e-2ac1-4806-8e0a-c323c9280113",
   "metadata": {},
   "source": [
    "### Exploratory-Data-Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8181d158-8982-4cdf-a742-acf4100a9e4f",
   "metadata": {},
   "source": [
    "Explore the relationship between interest rate and loan amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795cbf0-da9e-4f91-a8f3-b5c96111a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data between fully paid and charged off / defaulted loans\n",
    "paid_loans = sample_accepted_df[sample_accepted_df['loan_status'] == \"Fully Paid\"]\n",
    "defaulted_loans = sample_accepted_df[sample_accepted_df['loan_status'] == \"Charged Off/Default\"]\n",
    "\n",
    "# A hexbin is more appropriate due to the number of datapoints being plotted. The count of each hex is plotted on the right\n",
    "plt.hexbin(paid_loans['funded_amnt'], paid_loans['int_rate'], gridsize=20, label='Fully Paid')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Loan Amount')\n",
    "plt.xticks(rotation=45) \n",
    "plt.ylabel('Interest Rate')\n",
    "plt.title('Hexbin plot of Interest Rate vs Loan Amount')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=sample_accepted_df, x='loan_status', y='int_rate')\n",
    "plt.xticks(rotation=45) \n",
    "plt.title('Boxplot of Loan Amount by Loan Status')\n",
    "plt.xlabel('Loan Status')\n",
    "plt.ylabel('Interest Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c88490f-73eb-4ede-80ae-5e17abbc0728",
   "metadata": {},
   "source": [
    "Notice how there isn't much variation between late and \"in grace period\" loans, but there is between fully payed and defaulted / charged off loans. Charged off / defaulted loans have the highest median interest rate, with fully paid loans having one of the lowest. When considered with the hexplot, the majority of loans fall between $5,000 and $10,000, with an interest rate of approximately 12%, with the defaulted / charged off loans have a much higher interest rate, being further from the central grouping of data on the hex plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca58ad45-66a0-4101-a0e3-ac89b8829abd",
   "metadata": {},
   "source": [
    "### Feature-Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5339ae-e117-46c6-a94c-e84295ab4a9e",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Loan-to-income ratio\n",
    "- Loan purpose one hot encoding\n",
    "- simplify loan grade and subgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf738ba9-f35f-44f5-b673-5492d9d38735",
   "metadata": {},
   "source": [
    "purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e52df29-ef46-4271-bc0e-e29edce560f0",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a935c1-af40-4292-9db5-1b7d3b383943",
   "metadata": {},
   "source": [
    "### Resources used:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9042de83-cf0d-41c1-b9b6-6e53a25bf0fa",
   "metadata": {},
   "source": [
    "- https://stackoverflow.com/questions/51325601/how-to-stop-my-pandas-data-table-from-being-truncated-when-printed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loans_capstone",
   "language": "python",
   "name": "loans_capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
